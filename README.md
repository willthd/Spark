## Spark 기초 개념 및 특징

* 스파크 Dataframe은 수천 대의 컴퓨터에 분산되어 있다.(Python과 R은 일반적으로 분산 컴퓨터가 아닌 단일 컴퓨터에 존재)
* 스파크는 모든 익스큐터가 병렬로 작업을 수행할 수 있도록 파티션이라 불리는 청크 단위로 데이터를 분할한다.
* Transformation은 좁은 의존성과 넓은 의존성 두 가지 유형이 있다. 좁은 의존성은 모든 작업이 메모리에서 일어나며, 넓은 의존성은 디스크에 저장한다.
* **셔플(shuffle)** : 스파크가 클러스터에서 파티션을 교환하는 것
* 스파크는 셔플 수행 시 기본적으로 200개의 셔플 파티션을 생성한다.
* <u>스파크는 해당 DataFrame이나 자신의 원본 DataFrame에 액션이 호출되기 전까지 데이터를 읽지 않는다. 액션을 지정하면 스파크 잡이 시작된다.</u> 이렇듯 스파크가 연산 그래프를 처리하기 직전까지 기다리는 동작 방식을 **지연 연산**이라고 한다.
* createOrReplaceTempView 메서드를 호출하면 모든 DataFrame을 테이블이나 뷰로 만들 수 있다.(SQL로 접근 가능해짐)
* 스파크는 SQL 쿼리를 DataFrame 코드와 같은 샐행 계획으로 컴파일하므로 둘 사이의 성능 차이는 없다.

